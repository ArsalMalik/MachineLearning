------------------ Bagging Classifier -------------------
***** Random Search *****
Cross-Validation:10 and number of iterations:30
# Tuning hyper-parameters for accuracy

Best parameters and scores set found on development set:
{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': False, 'max_samples': 0.5, 'max_features': 1.0, 'n_estimators': 20}
0.963734567901

Random scores on development set:
0.863 (+/-0.031) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 20}
0.961 (+/-0.047) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': True, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 5}
0.911 (+/-0.034) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'), 'bootstrap': True, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 10}
0.704 (+/-0.010) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': False, 'max_samples': 0.5, 'max_features': 0.5, 'n_estimators': 10}
0.955 (+/-0.039) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': False, 'max_samples': 0.3, 'max_features': 1.0, 'n_estimators': 20}
0.898 (+/-0.043) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'), 'bootstrap': False, 'max_samples': 0.5, 'max_features': 1.0, 'n_estimators': 5}
0.851 (+/-0.051) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': False, 'max_samples': 0.3, 'max_features': 0.5, 'n_estimators': 15}
0.750 (+/-0.086) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': True, 'max_samples': 0.3, 'max_features': 0.5, 'n_estimators': 15}
0.826 (+/-0.073) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': True, 'max_samples': 0.9, 'max_features': 0.5, 'n_estimators': 15}
0.704 (+/-0.014) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 0.5, 'n_estimators': 20}
0.755 (+/-0.093) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 0.5, 'n_estimators': 15}
0.704 (+/-0.014) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': True, 'max_samples': 0.5, 'max_features': 0.5, 'n_estimators': 20}
0.851 (+/-0.036) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), 'bootstrap': True, 'max_samples': 0.5, 'max_features': 1.0, 'n_estimators': 10}
0.964 (+/-0.035) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': False, 'max_samples': 0.5, 'max_features': 1.0, 'n_estimators': 20}
0.785 (+/-0.083) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), 'bootstrap': True, 'max_samples': 0.5, 'max_features': 0.5, 'n_estimators': 10}
0.895 (+/-0.016) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': True, 'max_samples': 0.9, 'max_features': 1.0, 'n_estimators': 15}
0.946 (+/-0.048) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best'), 'bootstrap': False, 'max_samples': 0.3, 'max_features': 1.0, 'n_estimators': 5}
0.856 (+/-0.073) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': False, 'max_samples': 0.5, 'max_features': 1.0, 'n_estimators': 5}
0.880 (+/-0.066) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'), 'bootstrap': True, 'max_samples': 0.5, 'max_features': 1.0, 'n_estimators': 5}
0.877 (+/-0.039) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 15}
0.704 (+/-0.011) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': True, 'max_samples': 0.3, 'max_features': 0.5, 'n_estimators': 15}
0.921 (+/-0.027) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'), 'bootstrap': False, 'max_samples': 0.9, 'max_features': 1.0, 'n_estimators': 20}
0.862 (+/-0.038) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), 'bootstrap': True, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 5}
0.840 (+/-0.035) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 15}
0.870 (+/-0.050) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 10}
0.840 (+/-0.035) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': True, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 15}
0.762 (+/-0.080) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False), 'bootstrap': False, 'max_samples': 0.3, 'max_features': 0.5, 'n_estimators': 5}
0.802 (+/-0.068) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform'), 'bootstrap': False, 'max_samples': 0.9, 'max_features': 0.5, 'n_estimators': 10}
0.704 (+/-0.010) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'bootstrap': True, 'max_samples': 0.7, 'max_features': 0.5, 'n_estimators': 20}
0.877 (+/-0.039) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False), 'bootstrap': False, 'max_samples': 0.7, 'max_features': 1.0, 'n_estimators': 20}


  ------------------ Bagging Classifier -------------------
  ***** Random Search *****
  Cross-Validation:10 and number of iterations:30
  # Tuning hyper-parameters for accuracy

  Best parameters and scores set found on development set:
  {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter='best'), 'n_estimators': 30, 'bootstrap': False, 'max_samples': 0.9}
  0.974537037037

  Random scores on development set:
  0.870 (+/-0.056) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 'n_estimators': 50, 'bootstrap': False, 'max_samples': 0.5}
  0.865 (+/-0.072) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 10, 'bootstrap': False, 'max_samples': 0.9}
  0.852 (+/-0.055) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 50, 'bootstrap': True, 'max_samples': 0.5}
  0.854 (+/-0.062) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 10, 'bootstrap': False, 'max_samples': 0.5}
  0.870 (+/-0.068) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 20, 'bootstrap': False, 'max_samples': 0.9}
  0.956 (+/-0.038) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter='best'), 'n_estimators': 5, 'bootstrap': True, 'max_samples': 0.7}
  0.880 (+/-0.040) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 'n_estimators': 5, 'bootstrap': False, 'max_samples': 0.7}
  0.857 (+/-0.055) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 15, 'bootstrap': False, 'max_samples': 0.5}
  0.910 (+/-0.031) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 10, 'bootstrap': True, 'max_samples': 0.9}
  0.917 (+/-0.020) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 20, 'bootstrap': True, 'max_samples': 0.7}
  0.907 (+/-0.033) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 5, 'bootstrap': True, 'max_samples': 0.9}
  0.858 (+/-0.058) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 30, 'bootstrap': True, 'max_samples': 0.7}
  0.864 (+/-0.063) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 'n_estimators': 10, 'bootstrap': True, 'max_samples': 0.5}
  0.904 (+/-0.035) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 50, 'bootstrap': False, 'max_samples': 0.5}
  0.908 (+/-0.027) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 20, 'bootstrap': True, 'max_samples': 0.9}
  0.968 (+/-0.022) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter='best'), 'n_estimators': 30, 'bootstrap': True, 'max_samples': 0.9}
  0.882 (+/-0.054) for {'base_estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False), 'n_estimators': 50, 'bootstrap': True, 'max_samples': 0.7}
  0.975 (+/-0.024) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter='best'), 'n_estimators': 30, 'bootstrap': False, 'max_samples': 0.9}
  0.920 (+/-0.027) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 20, 'bootstrap': False, 'max_samples': 0.9}
  0.830 (+/-0.068) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'n_estimators': 15, 'bootstrap': True, 'max_samples': 0.5}
  0.848 (+/-0.053) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'n_estimators': 15, 'bootstrap': False, 'max_samples': 0.9}
  0.911 (+/-0.029) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 50, 'bootstrap': True, 'max_samples': 0.7}
  0.971 (+/-0.030) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter='best'), 'n_estimators': 15, 'bootstrap': False, 'max_samples': 0.9}
  0.869 (+/-0.063) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 20, 'bootstrap': True, 'max_samples': 0.9}
  0.867 (+/-0.072) for {'base_estimator': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
            intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
            penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
            verbose=0, warm_start=False), 'n_estimators': 15, 'bootstrap': False, 'max_samples': 0.9}
  0.828 (+/-0.065) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'n_estimators': 5, 'bootstrap': True, 'max_samples': 0.5}
  0.965 (+/-0.033) for {'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
              max_features=None, max_leaf_nodes=None,
              min_impurity_decrease=0.0, min_impurity_split=None,
              min_samples_leaf=1, min_samples_split=2,
              min_weight_fraction_leaf=0.0, presort=False, random_state=None,
              splitter='best'), 'n_estimators': 15, 'bootstrap': False, 'max_samples': 0.5}
  0.840 (+/-0.062) for {'base_estimator': MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True), 'n_estimators': 50, 'bootstrap': False, 'max_samples': 0.5}
  0.915 (+/-0.030) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 15, 'bootstrap': False, 'max_samples': 0.7}
  0.917 (+/-0.035) for {'base_estimator': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
             metric_params=None, n_jobs=1, n_neighbors=5, p=2,
             weights='uniform'), 'n_estimators': 20, 'bootstrap': False, 'max_samples': 0.7}
